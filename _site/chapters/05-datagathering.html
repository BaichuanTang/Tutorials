<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Data Gathering - Textbooks with Jupyter</title>
<meta name="description" content="Data Gathering">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Textbooks with Jupyter">
<meta property="og:title" content="Data Gathering">
<meta property="og:url" content="http://localhost:4000/textbooks-with-jupyter/chapters/05-DataGathering">


  <meta property="og:description" content="Data Gathering">







  <meta property="article:published_time" content="2018-09-21T12:22:31-07:00">





  

  


<link rel="canonical" href="http://localhost:4000/textbooks-with-jupyter/chapters/05-DataGathering">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Chris Holdgraf",
      "url": "http://localhost:4000/textbooks-with-jupyter",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/textbooks-with-jupyter/feed.xml" type="application/atom+xml" rel="alternate" title="Textbooks with Jupyter Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/textbooks-with-jupyter/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->


<!-- end custom head snippets -->

    <link rel="stylesheet" href="/textbooks-with-jupyter/assets/css/notebook-markdown.css">
    <link rel="stylesheet" href="/textbooks-with-jupyter/assets/css/custom.css">
    <link rel="shortcut icon" type="image/png" href="/textbooks-with-jupyter/favicon.png">
    <script src="https://cdn.jsdelivr.net/npm/clipboard@1/dist/clipboard.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js"></script>
  </head>

  <body class="layout--textbook">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

    <div class="initial-content">
      



<div id="main" class="textbook" role="main">
  <div id="textbook_wrapper">
    
  <div class="sidebar sticky textbook">
  
  
    <img src="/textbooks-with-jupyter/images/logo/logo.png" class="textbook_logo" />
    

    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/"><span class="nav__sub-title">Home</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/00-Introduction"><span class="nav__sub-title">00-introduction</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/01-JupyterNotebooks"><span class="nav__sub-title">01-jupyternotebooks</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/02-DataAnalysis"><span class="nav__sub-title">02-dataanalysis</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/03-Python"><span class="nav__sub-title">03-python</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/04-DataSciencePython"><span class="nav__sub-title">04-datasciencepython</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/05-DataGathering"><span class="nav__sub-title">05-datagathering</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/06-DataWrangling"><span class="nav__sub-title">06-datawrangling</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/07-DataCleaning"><span class="nav__sub-title">07-datacleaning</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/08-DataPrivacy&Anonymization"><span class="nav__sub-title">08-dataprivacy&anonymization</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/09-DataVisualization"><span class="nav__sub-title">09-datavisualization</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/10-Distributions"><span class="nav__sub-title">10-distributions</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/11-TestingDistributions"><span class="nav__sub-title">11-testingdistributions</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/13-OrdinaryLeastSquares"><span class="nav__sub-title">13-ordinaryleastsquares</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/14-LinearModels"><span class="nav__sub-title">14-linearmodels</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/15-Clustering"><span class="nav__sub-title">15-clustering</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/16-DimensionalityReduction"><span class="nav__sub-title">16-dimensionalityreduction</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/17-Classification"><span class="nav__sub-title">17-classification</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/18-NaturalLanguageProcessing"><span class="nav__sub-title">18-naturallanguageprocessing</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/A1-PythonPackages"><span class="nav__sub-title">A1-pythonpackages</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/A2-Git"><span class="nav__sub-title">A2-git</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/textbooks-with-jupyter/chapters/README"><span class="nav__sub-title">Readme</span></a>
        

        
      </li>
    
  </ul>
</nav>

    

  
  </div>


    <article class="page textbook" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="headline" content="Data Gathering">
      <meta itemprop="description" content="Data Gathering">
      <meta itemprop="datePublished" content="September 21, 2018">
      

      <div class="page__inner-wrap">
        
          <header>
            <h1 id="page-title" class="page__title" itemprop="headline">Data Gathering
</h1>
          </header>
        

        <section class="page__content" itemprop="text">
          
            

<!-- TOC will only show up if it has at least one item -->


  <aside class="sidebar__right">
    <nav class="toc">
      <header><h4 class="nav__title"><i class="fas fa-list-ul"></i>   On this page</h4></header>
      <ul class="toc__menu">
  <li><a href="#where-to-get-data">Where to get Data</a>
    <ul>
      <li><a href="#the-web">The Web</a></li>
      <li><a href="#other-than-the-web">Other than the Web</a></li>
      <li><a href="#data-gathering-skills">Data Gathering Skills</a></li>
    </ul>
  </li>
  <li><a href="#data-repositories">Data Repositories</a></li>
  <li><a href="#databases">Databases</a>
    <ul>
      <li><a href="#structured-query-language---sql">Structured Query Language - SQL</a></li>
    </ul>
  </li>
  <li><a href="#application-program-interfaces-apis">Application Program Interfaces (APIs)</a>
    <ul>
      <li><a href="#launching-url-requests-from-python">Launching URL Requests from Python</a></li>
    </ul>
  </li>
  <li><a href="#web-scraping">Web Scraping</a>
    <ul>
      <li><a href="#apis-vs-web-scraping">APIs vs. Web Scraping</a></li>
    </ul>
  </li>
</ul>
    </nav>
  </aside>


          
          <!-- INTERACT LINKS -->

    
    
    <a class="interact-button" href="https://mybinder.org/v2/gh/choldgraf/textbooks-with-jupyter/master?filepath=notebooks%2F05-DataGathering.ipynb">Interact</a>


          
<div class="alert alert-success">
Data Gathering is simply the process of collecting your data together.
</div>

<p>This notebook covers strategies you can use to gather data for an analysis.</p>

<p>If you want to move on to first working on data analyses (with provided data) you can move onto the next tutorials, and come back to this one later.</p>

<p>Data gathering can encompass anything from launching a data collection project, web scraping, pulling from a database, downloading data in bulk.</p>

<p>It might even include simply calling someone to ask if you can use some of their data.</p>

<h2 id="where-to-get-data">Where to get Data</h2>

<h3 id="the-web">The Web</h3>

<p>The web is absolutely full of data or ways to get data, either by hosting <strong>data repositories</strong> from which you can download data, by offering <strong>APIs</strong> through which you can request specific data from particular applications, or as data itself, such that you can use <strong>web scraping</strong> to extract data directly from websites.</p>

<h3 id="other-than-the-web">Other than the Web</h3>

<p>Not all data is indexed or accessible on the web, at least not publicly.</p>

<p>Sometimes finding data means chasing down data wherever it might be.</p>

<p>If there is some particular data you need, you can try to figure out who might have it, and get in touch to see if it might be available.</p>

<h3 id="data-gathering-skills">Data Gathering Skills</h3>
<p>Depending on your gathering method, you will likely have to do some combination of the following:</p>
<ul>
  <li>Download data files from repositories</li>
  <li>Read data files into python</li>
  <li>Use APIs</li>
  <li>Query databases</li>
  <li>Call someone and ask them to send you a harddrive</li>
</ul>

<h2 id="data-repositories">Data Repositories</h2>

<div class="alert alert-success">
A Data Repository is basically just a place that data is stored. For our purposes, it is a place you can download data from. 
</div>

<div class="alert alert-info">
There is a curated list of good data source included in the 
&lt;a href=https://github.com/COGS108/Projects&gt;project materials&lt;/a&gt;.
</div>

<h2 id="databases">Databases</h2>

<div class="alert alert-success">
A database is an organized collection of data. More formally, 'database' refers to a set of related data, and the way it is organized. 
</div>

<h3 id="structured-query-language---sql">Structured Query Language - SQL</h3>

<div class="alert alert-success">
SQL (pronounced 'sequel') is a language used to 'communicate' with databases, making queries to request particular data from them.
</div>

<div class="alert alert-info">
There is a useful introduction and tutorial to SQL
&lt;a href=http://www.sqlcourse.com/intro.html&gt;here&lt;/a&gt;
as well as some useful 'cheat sheets' 
&lt;a href=http://www.cheat-sheets.org/sites/sql.su/&gt;here&lt;/a&gt;
and
&lt;a href=http://www.sqltutorial.org/wp-content/uploads/2016/04/SQL-cheat-sheet.pdf&gt;here&lt;/a&gt;.
</div>

<p>SQL is the standard, and most popular, way to interface with relational databases.</p>

<p>Note: None of the rest of the tutorials presume or require any knowledge of SQL.</p>

<p>You can look into it if you want, or if it is relevant to accessing some data you want to analyze, but it is not required for this set of tutorials.</p>

<h2 id="application-program-interfaces-apis">Application Program Interfaces (APIs)</h2>

<div class="alert alert-success">
APIs are basically a way for software to talk to software - it is an interface into an application / website / database designed for software.
</div>

<div class="alert alert-info">
For a simple explanation of APIs go
&lt;a href=https://medium.freecodecamp.com/what-is-an-api-in-english-please-b880a3214a82&gt;here&lt;/a&gt;
or for a much broader, more technical, overview try
&lt;a href=https://medium.com/@mattburgess/apis-a-basic-primer-f8250602597d&gt;here&lt;/a&gt;.
</div>

<p>APIs offer a lot of functionality - you can send requests to the application to do all kinds of actions. In fact, any application interface that is designed to be used programatically is an API, including, for example, interfaces for using packages of code.</p>

<p>One of the many things that APIs do, and offer, is a way to query and access data from particular applications / databases. The benefit of using APIs for data gathering purposes is that they typically return data in nicely structured formats, that are relatively easy to analyze.</p>

<h3 id="launching-url-requests-from-python">Launching URL Requests from Python</h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Imports</span>
<span class="c">#  requests lets you make http requests from python</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
</code></pre></div></div>

<p>In practice, APIs are usually special URLs that return raw data (json or XML) as opposed to a web page to be rendered for human viewers (html). Find the documentation for a particular API to see how you send requests to access whatever data you want. For example, let’s try the Github API.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Request data from the Github API on a particular user</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://api.github.com/users/tomdonoghue'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># In this case, the content we get back is a json file</span>
<span class="n">page</span><span class="o">.</span><span class="n">content</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>b'{"login":"TomDonoghue","id":7727566,"avatar_url":"https://avatars0.githubusercontent.com/u/7727566?v=4","gravatar_id":"","url":"https://api.github.com/users/TomDonoghue","html_url":"https://github.com/TomDonoghue","followers_url":"https://api.github.com/users/TomDonoghue/followers","following_url":"https://api.github.com/users/TomDonoghue/following{/other_user}","gists_url":"https://api.github.com/users/TomDonoghue/gists{/gist_id}","starred_url":"https://api.github.com/users/TomDonoghue/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/TomDonoghue/subscriptions","organizations_url":"https://api.github.com/users/TomDonoghue/orgs","repos_url":"https://api.github.com/users/TomDonoghue/repos","events_url":"https://api.github.com/users/TomDonoghue/events{/privacy}","received_events_url":"https://api.github.com/users/TomDonoghue/received_events","type":"User","site_admin":false,"name":"Tom","company":"UC San Diego","blog":"tomdonoghue.github.io","location":"San Diego","email":null,"hireable":null,"bio":"Cognitive Science Grad Student @ UCSD. \\r\\nOn Twitter @TomDonoghue","public_repos":13,"public_gists":0,"followers":13,"following":35,"created_at":"2014-05-28T20:20:48Z","updated_at":"2018-01-09T04:15:59Z"}'
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># We can read in the json data with pandas</span>
<span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="s">'series'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>avatar_url             https://avatars0.githubusercontent.com/u/77275...
bio                    Cognitive Science Grad Student @ UCSD. \r\nOn ...
blog                                               tomdonoghue.github.io
company                                                     UC San Diego
created_at                                          2014-05-28T20:20:48Z
email                                                               None
events_url             https://api.github.com/users/TomDonoghue/event...
followers                                                             13
followers_url          https://api.github.com/users/TomDonoghue/follo...
following                                                             35
following_url          https://api.github.com/users/TomDonoghue/follo...
gists_url              https://api.github.com/users/TomDonoghue/gists...
gravatar_id                                                             
hireable                                                            None
html_url                                  https://github.com/TomDonoghue
id                                                               7727566
location                                                       San Diego
login                                                        TomDonoghue
name                                                                 Tom
organizations_url          https://api.github.com/users/TomDonoghue/orgs
public_gists                                                           0
public_repos                                                          13
received_events_url    https://api.github.com/users/TomDonoghue/recei...
repos_url                 https://api.github.com/users/TomDonoghue/repos
site_admin                                                         False
starred_url            https://api.github.com/users/TomDonoghue/starr...
subscriptions_url      https://api.github.com/users/TomDonoghue/subsc...
type                                                                User
updated_at                                          2018-01-09T04:15:59Z
url                             https://api.github.com/users/TomDonoghue
dtype: object
</code></pre></div></div>

<div class="alert alert-info">
This
&lt;a href=http://www.webopedia.com/TERM/A/API.html&gt;list&lt;/a&gt;
includes a collection of commonly used and available APIs. 
</div>

<h2 id="web-scraping">Web Scraping</h2>

<div class="alert alert-success">
Web scraping is when you (programmatically) extract data from websites.
</div>

<div class="alert alert-info">
&lt;a href=https://en.wikipedia.org/wiki/Web_scraping&gt;Wikipedia&lt;/a&gt;
has a useful page on web scraping.
</div>

<p>Note that the following section uses the ‘BeautifulSoup’ module, which is not part of the standard anaconda distribution.</p>

<p>If you do not have BeautifulSoup, and want to get it to run this section, you can uncomment the cell below, and run it, to install BeautifulSoup in your current Python environment. You only have to do this once.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#import sys</span>
<span class="c">#!conda install --yes --prefix {sys.prefix} beautifulsoup4</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Import BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Set the URL for the page we wish to scrape</span>
<span class="n">site_url</span> <span class="o">=</span> <span class="s">'https://en.wikipedia.org/wiki/Data_science'</span>

<span class="c"># Launch the URL request, to get the page</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">site_url</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Print out the first 1000 characters of the scraped web page</span>
<span class="n">page</span><span class="o">.</span><span class="n">content</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1000</span><span class="p">]</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>b'<span class="cp">&lt;!DOCTYPE html&gt;</span>\n<span class="nt">&lt;html</span> <span class="na">class=</span><span class="s">"client-nojs"</span> <span class="na">lang=</span><span class="s">"en"</span> <span class="na">dir=</span><span class="s">"ltr"</span><span class="nt">&gt;</span>\n<span class="nt">&lt;head&gt;</span>\n<span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">"UTF-8"</span><span class="nt">/&gt;</span>\n<span class="nt">&lt;title&gt;</span>Data science - Wikipedia<span class="nt">&lt;/title&gt;</span>\n<span class="nt">&lt;script&gt;</span><span class="nb">document</span><span class="p">.</span><span class="nx">documentElement</span><span class="p">.</span><span class="nx">className</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">documentElement</span><span class="p">.</span><span class="nx">className</span><span class="p">.</span><span class="nx">replace</span><span class="p">(</span> <span class="sr">/</span><span class="se">(</span><span class="sr">^|</span><span class="se">\\</span><span class="sr">s</span><span class="se">)</span><span class="sr">client-nojs</span><span class="se">(\\</span><span class="sr">s|$</span><span class="se">)</span><span class="sr">/</span><span class="p">,</span> <span class="s2">"$1client-js$2"</span> <span class="p">);</span><span class="nt">&lt;/script&gt;</span>\n<span class="nt">&lt;script&gt;</span><span class="p">(</span><span class="nb">window</span><span class="p">.</span><span class="nx">RLQ</span><span class="o">=</span><span class="nb">window</span><span class="p">.</span><span class="nx">RLQ</span><span class="o">||</span><span class="p">[]).</span><span class="nx">push</span><span class="p">(</span><span class="kd">function</span><span class="p">(){</span><span class="nx">mw</span><span class="p">.</span><span class="nx">config</span><span class="p">.</span><span class="kd">set</span><span class="p">({</span><span class="s2">"wgCanonicalNamespace"</span><span class="p">:</span><span class="s2">""</span><span class="p">,</span><span class="s2">"wgCanonicalSpecialPageName"</span><span class="p">:</span><span class="kc">false</span><span class="p">,</span><span class="s2">"wgNamespaceNumber"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">"wgPageName"</span><span class="p">:</span><span class="s2">"Data_science"</span><span class="p">,</span><span class="s2">"wgTitle"</span><span class="p">:</span><span class="s2">"Data science"</span><span class="p">,</span><span class="s2">"wgCurRevisionId"</span><span class="p">:</span><span class="mi">822535327</span><span class="p">,</span><span class="s2">"wgRevisionId"</span><span class="p">:</span><span class="mi">822535327</span><span class="p">,</span><span class="s2">"wgArticleId"</span><span class="p">:</span><span class="mi">35458904</span><span class="p">,</span><span class="s2">"wgIsArticle"</span><span class="p">:</span><span class="kc">true</span><span class="p">,</span><span class="s2">"wgIsRedirect"</span><span class="p">:</span><span class="kc">false</span><span class="p">,</span><span class="s2">"wgAction"</span><span class="p">:</span><span class="s2">"view"</span><span class="p">,</span><span class="s2">"wgUserName"</span><span class="p">:</span><span class="kc">null</span><span class="p">,</span><span class="s2">"wgUserGroups"</span><span class="p">:[</span><span class="s2">"*"</span><span class="p">],</span><span class="s2">"wgCategories"</span><span class="p">:[</span><span class="s2">"Use dmy dates from December 2012"</span><span class="p">,</span><span class="s2">"Information science"</span><span class="p">,</span><span class="s2">"Computer occupations"</span><span class="p">,</span><span class="s2">"Computational fields of study"</span><span class="p">,</span><span class="s2">"Data analysis"</span><span class="p">],</span><span class="s2">"wgBreakFrames"</span><span class="p">:</span><span class="kc">false</span><span class="p">,</span><span class="s2">"wgPageContentLanguage"</span><span class="p">:</span><span class="s2">"en"</span><span class="p">,</span><span class="s2">"wgPageContentModel"</span><span class="p">:</span><span class="s2">"wikitext"</span><span class="p">,</span><span class="s2">"wgSeparatorTransformTable"</span><span class="p">:[</span><span class="s2">""</span><span class="p">,</span><span class="s2">""</span><span class="p">],</span><span class="s2">"wgDigitTransformTable"</span><span class="p">:[</span><span class="s2">""</span><span class="p">,</span><span class="s2">""</span><span class="p">],</span><span class="s2">"wgDefaultDateFormat"</span><span class="p">:</span><span class="s2">"dmy"</span><span class="p">,</span><span class="s2">"wgMonthNames"</span><span class="p">:[</span><span class="s2">""</span><span class="p">,</span><span class="s2">"Ja'
</span></code></pre></div></div>

<p>Note that the source of the scraped web-page is a messy pile of HTML.</p>

<p>There is a lot of information in there, but with no clear organization. There is some structure in the page though, delineated by HTML tags, etc, we just need to use them to parse out the data. We can do that with BeautifulSoup, which takes in messy documents like this, and parses them based on a specified format.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Parse the webpage with Beautiful Soup, using a html parser</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># With the parsed soup object, we can select particular segments of the web page</span>

<span class="c"># Print out the page title</span>
<span class="k">print</span><span class="p">(</span><span class="s">'TITLE: </span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">title</span><span class="p">)</span>

<span class="c"># Print out the first p-tag</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">P-TAG:</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'p'</span><span class="p">))</span>
</code></pre></div></div>

<div class="output_stream highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TITLE: 

&lt;title&gt;Data science - Wikipedia&lt;/title&gt;

P-TAG:

&lt;p&gt;&lt;b&gt;Data science&lt;/b&gt;, also known as &lt;b&gt;data-driven science&lt;/b&gt;, is an interdisciplinary field of scientific methods, processes, and systems to extract &lt;a href="/wiki/Knowledge" title="Knowledge"&gt;knowledge&lt;/a&gt; or insights from &lt;a href="/wiki/Data" title="Data"&gt;data&lt;/a&gt; in various forms, either structured or unstructured,&lt;sup class="reference" id="cite_ref-:0_1-0"&gt;&lt;a href="#cite_note-:0-1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;sup class="reference" id="cite_ref-2"&gt;&lt;a href="#cite_note-2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; similar to &lt;a href="/wiki/Data_mining" title="Data mining"&gt;data mining&lt;/a&gt;.&lt;/p&gt;

</code></pre></div></div>

<p>From the soup object, you can explore that the page is much more organized, and in such a way that you can extract particular components of interest.</p>

<p>Note that it is still ‘messy’ in other ways, in that there might or might not be a systematic structure to how the page is laid out, and it still might take a lot of work to extract the particular information you want from it.</p>

<h3 id="apis-vs-web-scraping">APIs vs. Web Scraping</h3>

<p>Web scraping is distinct from using an API, even though many APIs may be accessed over the internet. Web scraping is different in that you are (programmatically) navigating through the internet, and extracting data of interest.</p>

<p>Note:
Be aware that scraping data from websites (without using APIs) can often be an involved project itself - scraping sites can take a considerable amount of tuning to get the data you want.</p>

<p>Be aware that data presented on websites may not be well structured, or in an organzed format that lends itself to easy analysis.</p>

<p>If you try scraping websites, also make sure you are allowed to scrape the data, and follow the websites terms of service.</p>

          
        </section>

        <footer class="page__meta">
          
          


        </footer>

        

        
  <nav class="pagination">
    
      <a href="/textbooks-with-jupyter/chapters/04-DataSciencePython" class="pagination--pager" title="04-datasciencepython
">Previous</a>
    
    
      <a href="/textbooks-with-jupyter/chapters/06-DataWrangling" class="pagination--pager" title="06-datawrangling
">Next</a>
    
  </nav>


      </div>

      
    </article>
  </div>
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    

    
  <script src="/textbooks-with-jupyter/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




<script src="/textbooks-with-jupyter/assets/js/lunr/lunr.min.js"></script>
<script src="/textbooks-with-jupyter/assets/js/lunr/lunr-store.js"></script>
<script src="/textbooks-with-jupyter/assets/js/lunr/lunr-en.js"></script>




    <!-- Custom scripts to load after site JS is loaded -->

    <!-- Custom HTML used for the textbooks -->
<!-- Configure, then load MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      processEnvironments: true
    }
  };
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full,Safe" type="text/javascript"></script>


<script type="text/javascript">
// --- To auto-embed hub URLs in interact links if given in a RESTful fashion ---
function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return jQuery.param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = $("a").each(function() {
    var href = this.href;
    // If the link is an internal link...
    if (href.search("http://localhost:4000") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['hub'] = hub;
      } else {
        // Create the REST params
        params = {'hub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + jQuery.param(params);
      this.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}

  // Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    hubUrl = rest['hub'];
    if (hubUrl !== undefined) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);
      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      link = $("a.interact-button")[0];
      if (link !== undefined) {
          // Update the interact link URL
          var href = link.getAttribute('href');
          if ('binder' == 'binder') {
            // If binder links exist, we need to re-work them for jupyterhub
            first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
            href = first + '?' + binder2Jupyterhub(href);
          } else {
            // If JupyterHub links, we only need to replace the hub url
            href = href.replace("https://mybinder.org", hubUrl);
          }
          link.setAttribute('href', decodeURIComponent(href));

          // Add text after interact link saying where we're launching
          hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
          $("a.interact-button").after($('<div class="interact-context">on ' + hubUrlNoHttp + '</div>'));

      }
      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

// --- Highlight the part of sidebar for current page ---

// helper to replace trailing slash
function replaceSlash(string)
{
    return string.replace(/\/$/, "");
}

// Add a class to the current page in the sidebar
function highlightSidebarCurrentPage()
{
  var currentpage = location.href;
  var links = $('.sidebar .nav__items a');
  var ii = 0;
  for(ii; ii < links.length; ii++) {
    var link = links[ii];
    if(replaceSlash(link.href) == replaceSlash(currentpage)) {
      // Add CSS for styling
      link.classList.add("current");
      // Scroll to this element
      $('div.sidebar').scrollTop(link.offsetTop - 300);
    }
  }
}

// --- Set up copy/paste for code blocks ---
function addCopyButtonToCode(){
  // get all <code> elements
  var allCodeBlocksElements = $( "div.input_area code, div.highlighter-rouge code" );

  allCodeBlocksElements.each(function(ii) {
   	// add different id for each code block

  	// target
    var currentId = "codeblock" + (ii + 1);
    $(this).attr('id', currentId);

    //trigger
    var clipButton = '<button class="btn copybtn" data-clipboard-target="#' + currentId + '"><img src="https://clipboardjs.com/assets/images/clippy.svg" width="13" alt="Copy to clipboard"></button>';
       $(this).after(clipButton);
    });

    new Clipboard('.btn');
}

// Run scripts when page is loaded
$(document).ready(function () {
  // Add anchors to H1 etc links
  anchors.add();
  // Highlight current page in sidebar
  highlightSidebarCurrentPage();
  // Add copy button to code blocks
  addCopyButtonToCode();
  // Update the Interact link if a REST param given
  updateInteractLink();
});
</script>

  </body>
</html>
